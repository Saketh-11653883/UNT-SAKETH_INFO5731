{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saketh-11653883/UNT-SAKETH_INFO5731/blob/main/Kaveti_saketh_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "1. Features (text representation) used for topic modeling.\n",
        "\n",
        "2. Top 10 clusters for topic modeling.\n",
        "\n",
        "3. Summarize and describe the topic for each cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6R_il1-CH1d",
        "outputId": "fc43c1ea-590c-4734-e814-c9c923d65249"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PuFPKhC0m1fd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim import corpora, models\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('Antman_reviews_annotated.csv')"
      ],
      "metadata": {
        "id": "4avS1JsyEGBn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "emrlJaWSEF4f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords and single character tokens\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words and len(word) > 1]\n",
        "    # Lemmatization\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return lemmatized_tokens"
      ],
      "metadata": {
        "id": "J6ddQ1ErEFk9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['clean_text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "VKFdTLbzEFhW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming clean_text_series contains preprocessed text data\n",
        "clean_text_series = df['clean_text'].tolist()\n",
        "\n",
        "# Initialize Dictionary\n",
        "dictionary = Dictionary(clean_text_series)\n",
        "\n",
        "# Convert text data to bag-of-words representation\n",
        "corpus = [dictionary.doc2bow(text) for text in clean_text_series]"
      ],
      "metadata": {
        "id": "v_XCtfYaUCGw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LDA model\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPFWEblDEmzU",
        "outputId": "5f1385c7-d021-44f5-d8c4-95088b6ecfc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summarized topics\n",
        "topics_summary = lda_model.show_topics(num_topics=10, num_words=10)"
      ],
      "metadata": {
        "id": "AXFFpbTsEm9t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the summarized topics\n",
        "print(\"Summarized Topics:\")\n",
        "for topic_idx, summary in enumerate(topics_summary):\n",
        "    print(f\"Topic {topic_idx}: {summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6aNrnlS7BgK",
        "outputId": "19d0b1ab-eadf-4fad-a16f-5b51f9fa6ee5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized Topics:\n",
            "Topic 0: (0, '0.032*\"movi\" + 0.014*\"charact\" + 0.013*\"marvel\" + 0.011*\"kang\" + 0.010*\"quantum\" + 0.009*\"mcu\" + 0.009*\"like\" + 0.009*\"set\" + 0.009*\"see\" + 0.008*\"film\"')\n",
            "Topic 1: (1, '0.025*\"movi\" + 0.016*\"time\" + 0.013*\"charact\" + 0.012*\"moment\" + 0.012*\"lot\" + 0.011*\"realli\" + 0.010*\"make\" + 0.009*\"action\" + 0.009*\"marvel\" + 0.008*\"help\"')\n",
            "Topic 2: (2, '0.044*\"movi\" + 0.021*\"charact\" + 0.019*\"phase\" + 0.014*\"could\" + 0.014*\"marvel\" + 0.012*\"kang\" + 0.011*\"antman\" + 0.010*\"see\" + 0.010*\"get\" + 0.010*\"like\"')\n",
            "Topic 3: (3, '0.020*\"film\" + 0.016*\"mcu\" + 0.012*\"marvel\" + 0.012*\"realli\" + 0.011*\"one\" + 0.011*\"movi\" + 0.010*\"hope\" + 0.009*\"kang\" + 0.009*\"someth\" + 0.009*\"even\"')\n",
            "Topic 4: (4, '0.025*\"movi\" + 0.020*\"mcu\" + 0.017*\"like\" + 0.013*\"kang\" + 0.012*\"film\" + 0.010*\"im\" + 0.010*\"major\" + 0.010*\"antman\" + 0.009*\"much\" + 0.009*\"charact\"')\n",
            "Topic 5: (5, '0.024*\"film\" + 0.016*\"charact\" + 0.013*\"one\" + 0.013*\"movi\" + 0.013*\"like\" + 0.012*\"villain\" + 0.009*\"didnt\" + 0.009*\"time\" + 0.009*\"watch\" + 0.008*\"thi\"')\n",
            "Topic 6: (6, '0.032*\"movi\" + 0.015*\"marvel\" + 0.012*\"antman\" + 0.011*\"like\" + 0.011*\"kang\" + 0.010*\"feel\" + 0.010*\"take\" + 0.010*\"dont\" + 0.009*\"get\" + 0.008*\"still\"')\n",
            "Topic 7: (7, '0.024*\"film\" + 0.014*\"mcu\" + 0.011*\"charact\" + 0.011*\"time\" + 0.010*\"like\" + 0.009*\"kang\" + 0.009*\"good\" + 0.009*\"scott\" + 0.009*\"antman\" + 0.007*\"thing\"')\n",
            "Topic 8: (8, '0.038*\"film\" + 0.017*\"antman\" + 0.014*\"charact\" + 0.011*\"one\" + 0.011*\"movi\" + 0.010*\"like\" + 0.010*\"mcu\" + 0.010*\"quantum\" + 0.009*\"time\" + 0.009*\"wasp\"')\n",
            "Topic 9: (9, '0.043*\"movi\" + 0.028*\"even\" + 0.018*\"charact\" + 0.015*\"dont\" + 0.014*\"care\" + 0.012*\"big\" + 0.012*\"one\" + 0.010*\"kang\" + 0.009*\"first\" + 0.008*\"get\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "1. Select features for the sentiment classification and explain why you select these features. Use a markdown cell to provide your explanation.\n",
        "\n",
        "2. Select two of the supervised learning algorithms/models from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build two sentiment classifiers respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "3. Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. The test set must be used for model evaluation in this step. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"Antman_reviews_annotated.csv\")"
      ],
      "metadata": {
        "id": "w8zYjdFpGjdi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['clean_text'], data['sentiment'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "dMaZu2ArGjLk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "s1hIytrCGjB7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select two supervised learning algorithms\n",
        "svm_classifier = LinearSVC()\n",
        "nb_classifier = MultinomialNB()"
      ],
      "metadata": {
        "id": "1IpDI2vXGi2Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate SVM classifier\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "svm_pred = svm_classifier.predict(X_test_tfidf)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred, average='weighted')\n",
        "svm_recall = recall_score(y_test, svm_pred, average='weighted')\n",
        "svm_f1 = f1_score(y_test, svm_pred, average='weighted')"
      ],
      "metadata": {
        "id": "Tb5NyRcTGyLu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate Naive Bayes classifier\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "nb_pred = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
        "nb_precision = precision_score(y_test, nb_pred, average='weighted')\n",
        "nb_recall = recall_score(y_test, nb_pred, average='weighted')\n",
        "nb_f1 = f1_score(y_test, nb_pred, average='weighted')"
      ],
      "metadata": {
        "id": "ypA2hxX7GyDa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "svm_cv_scores = cross_val_score(svm_classifier, X_train_tfidf, y_train, cv=5)\n",
        "nb_cv_scores = cross_val_score(nb_classifier, X_train_tfidf, y_train, cv=5)"
      ],
      "metadata": {
        "id": "SLkOYu5AG54L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(\"SVM Classifier Performance:\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"F1 Score:\", svm_f1)\n",
        "print(\"Cross-validation Scores:\", svm_cv_scores)\n",
        "\n",
        "print(\"\\nNaive Bayes Classifier Performance:\")\n",
        "print(\"Accuracy:\", nb_accuracy)\n",
        "print(\"Precision:\", nb_precision)\n",
        "print(\"Recall:\", nb_recall)\n",
        "print(\"F1 Score:\", nb_f1)\n",
        "print(\"Cross-validation Scores:\", nb_cv_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or2bctrmG5po",
        "outputId": "8c461b68-ef47-4ae2-85f6-506099a9b963"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Cross-validation Scores: [1. 1. 1. 1. 1.]\n",
            "\n",
            "Naive Bayes Classifier Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Cross-validation Scores: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(20 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878.\n",
        "\n",
        "1. Conduct necessary Explatory Data Analysis (EDA) and data cleaning steps on the given dataset. Split data for training and testing.\n",
        "2. Based on the EDA results, select a number of features for the regression model. Shortly explain why you select those features.\n",
        "3. Develop a regression model. The train set should be used.\n",
        "4. Evaluate performance of the regression model you developed using appropriate evaluation metrics. The test set should be used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "_6BKtxKjP3Hk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "8WRhttAIQQEg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "print(\"Train Data Info:\")\n",
        "print(df_train.info())\n",
        "print(\"\\nTest Data Info:\")\n",
        "print(df_test.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJMNITRQWk2",
        "outputId": "9380b6cb-a97d-45ae-9e7b-11629b751446"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     588 non-null    object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n",
            "None\n",
            "\n",
            "Test Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1459 entries, 0 to 1458\n",
            "Data columns (total 80 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1459 non-null   int64  \n",
            " 1   MSSubClass     1459 non-null   int64  \n",
            " 2   MSZoning       1455 non-null   object \n",
            " 3   LotFrontage    1232 non-null   float64\n",
            " 4   LotArea        1459 non-null   int64  \n",
            " 5   Street         1459 non-null   object \n",
            " 6   Alley          107 non-null    object \n",
            " 7   LotShape       1459 non-null   object \n",
            " 8   LandContour    1459 non-null   object \n",
            " 9   Utilities      1457 non-null   object \n",
            " 10  LotConfig      1459 non-null   object \n",
            " 11  LandSlope      1459 non-null   object \n",
            " 12  Neighborhood   1459 non-null   object \n",
            " 13  Condition1     1459 non-null   object \n",
            " 14  Condition2     1459 non-null   object \n",
            " 15  BldgType       1459 non-null   object \n",
            " 16  HouseStyle     1459 non-null   object \n",
            " 17  OverallQual    1459 non-null   int64  \n",
            " 18  OverallCond    1459 non-null   int64  \n",
            " 19  YearBuilt      1459 non-null   int64  \n",
            " 20  YearRemodAdd   1459 non-null   int64  \n",
            " 21  RoofStyle      1459 non-null   object \n",
            " 22  RoofMatl       1459 non-null   object \n",
            " 23  Exterior1st    1458 non-null   object \n",
            " 24  Exterior2nd    1458 non-null   object \n",
            " 25  MasVnrType     565 non-null    object \n",
            " 26  MasVnrArea     1444 non-null   float64\n",
            " 27  ExterQual      1459 non-null   object \n",
            " 28  ExterCond      1459 non-null   object \n",
            " 29  Foundation     1459 non-null   object \n",
            " 30  BsmtQual       1415 non-null   object \n",
            " 31  BsmtCond       1414 non-null   object \n",
            " 32  BsmtExposure   1415 non-null   object \n",
            " 33  BsmtFinType1   1417 non-null   object \n",
            " 34  BsmtFinSF1     1458 non-null   float64\n",
            " 35  BsmtFinType2   1417 non-null   object \n",
            " 36  BsmtFinSF2     1458 non-null   float64\n",
            " 37  BsmtUnfSF      1458 non-null   float64\n",
            " 38  TotalBsmtSF    1458 non-null   float64\n",
            " 39  Heating        1459 non-null   object \n",
            " 40  HeatingQC      1459 non-null   object \n",
            " 41  CentralAir     1459 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1459 non-null   int64  \n",
            " 44  2ndFlrSF       1459 non-null   int64  \n",
            " 45  LowQualFinSF   1459 non-null   int64  \n",
            " 46  GrLivArea      1459 non-null   int64  \n",
            " 47  BsmtFullBath   1457 non-null   float64\n",
            " 48  BsmtHalfBath   1457 non-null   float64\n",
            " 49  FullBath       1459 non-null   int64  \n",
            " 50  HalfBath       1459 non-null   int64  \n",
            " 51  BedroomAbvGr   1459 non-null   int64  \n",
            " 52  KitchenAbvGr   1459 non-null   int64  \n",
            " 53  KitchenQual    1458 non-null   object \n",
            " 54  TotRmsAbvGrd   1459 non-null   int64  \n",
            " 55  Functional     1457 non-null   object \n",
            " 56  Fireplaces     1459 non-null   int64  \n",
            " 57  FireplaceQu    729 non-null    object \n",
            " 58  GarageType     1383 non-null   object \n",
            " 59  GarageYrBlt    1381 non-null   float64\n",
            " 60  GarageFinish   1381 non-null   object \n",
            " 61  GarageCars     1458 non-null   float64\n",
            " 62  GarageArea     1458 non-null   float64\n",
            " 63  GarageQual     1381 non-null   object \n",
            " 64  GarageCond     1381 non-null   object \n",
            " 65  PavedDrive     1459 non-null   object \n",
            " 66  WoodDeckSF     1459 non-null   int64  \n",
            " 67  OpenPorchSF    1459 non-null   int64  \n",
            " 68  EnclosedPorch  1459 non-null   int64  \n",
            " 69  3SsnPorch      1459 non-null   int64  \n",
            " 70  ScreenPorch    1459 non-null   int64  \n",
            " 71  PoolArea       1459 non-null   int64  \n",
            " 72  PoolQC         3 non-null      object \n",
            " 73  Fence          290 non-null    object \n",
            " 74  MiscFeature    51 non-null     object \n",
            " 75  MiscVal        1459 non-null   int64  \n",
            " 76  MoSold         1459 non-null   int64  \n",
            " 77  YrSold         1459 non-null   int64  \n",
            " 78  SaleType       1458 non-null   object \n",
            " 79  SaleCondition  1459 non-null   object \n",
            "dtypes: float64(11), int64(26), object(43)\n",
            "memory usage: 912.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "# Drop columns with too many missing values\n",
        "missing_threshold = 0.5\n",
        "missing_cols_train = df_train.columns[df_train.isnull().mean() > missing_threshold]\n",
        "missing_cols_test = df_test.columns[df_test.isnull().mean() > missing_threshold]\n",
        "df_train.drop(columns=missing_cols_train, inplace=True)\n",
        "df_test.drop(columns=missing_cols_test, inplace=True)"
      ],
      "metadata": {
        "id": "eoytbz36QWix"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with mean for numerical columns\n",
        "num_cols_train = df_train.select_dtypes(include=np.number).columns\n",
        "num_cols_test = df_test.select_dtypes(include=np.number).columns\n",
        "df_train[num_cols_train] = df_train[num_cols_train].fillna(df_train[num_cols_train].mean())\n",
        "df_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].mean())"
      ],
      "metadata": {
        "id": "MUOaEgJrQWdi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting Features\n",
        "# Selecting numeric features\n",
        "numeric_features = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "selected_features = numeric_features[:10]  # Selecting the first 10 numeric features\n",
        "print(\"\\nSelected Features:\", selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph5tpDGGQWbB",
        "outputId": "90cad8dd-1878-4a4e-a18d-b4fa5f27f732"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected Features: ['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for training\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train['SalePrice']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "VEu11czpQWYF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Develop a regression model\n",
        "regression = LinearRegression()\n",
        "regression.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "i9eqmSEoQWUu",
        "outputId": "2fd4cb56-ffb1-406b-d577-dfcd005df93b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = regression.predict(X_test)"
      ],
      "metadata": {
        "id": "T3xt48fmQs__"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "r_squared = regression.score(X_test, y_test)\n",
        "print('\\nLinear Regression R-squared:', r_squared)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SpNQbSFQs7V",
        "outputId": "2f98c5fc-3b2b-4616-d2dd-7688e7904920"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear Regression R-squared: 0.7525976284545081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate root mean squared error\n",
        "mse = mean_squared_error(y_pred, y_test)\n",
        "rmse = np.sqrt(mse)\n",
        "print('Root Mean Squared Error:', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYeTjFFCQ5bj",
        "outputId": "d9b480f1-55cd-4389-e8e8-ef9c6d83bbfe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 43562.10387694369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BbswDvnEX-k"
      },
      "source": [
        "# **Question 4: Using Pre-trained LLMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKwKTnW1EX-k"
      },
      "source": [
        "(20 points)\n",
        "Utilize a **Pre-trained Language Model (PLM) from the Hugging Face Repository** for predicting sentiment polarities on the data you collected in Assignment 3.\n",
        "\n",
        "Then, choose a relevant LLM from their repository, such as GPT-3, BERT, or RoBERTa or any other related models.\n",
        "1. (5 points) Provide a brief description of the PLM you selected, including its original pretraining data sources,  number of parameters, and any task-specific fine-tuning if applied.\n",
        "2. (10 points) Use the selected PLM to perform the sentiment analysis on the data collected in Assignment 3. Only use the model in the **zero-shot** setting, NO finetuning is required. Evaluate performance of the model by comparing with the groundtruths (labels you annotated) on Accuracy, Precision, Recall, and F1 metrics.\n",
        "3. (5 points) Discuss the advantages and disadvantages of the selected PLM, and any challenges encountered during the implementation. This will enable a comprehensive understanding of the chosen LLM's applicability and effectiveness for the given task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BJgHWnOhFm-C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('Antman_reviews_annotated.csv')\n"
      ],
      "metadata": {
        "id": "zYY1F_vtOBPI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in the dataset:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzIiUw_OCuv",
        "outputId": "510afe59-5600-4c4b-c029-f704f032f8a4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in the dataset:\n",
            "document_id    0\n",
            "clean_text     0\n",
            "sentiment      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values in 'clean_text' and 'sentiment' columns\n",
        "df = df.dropna(subset=['clean_text', 'sentiment'])"
      ],
      "metadata": {
        "id": "T3FvIITpOCmb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize sentiment analysis pipeline\n",
        "emotion_pipeline = pipeline(\"sentiment-analysis\", model=\"distilroberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KmxkMhOOCag",
        "outputId": "8d76852b-9852-4131-85bd-ad60205f9013"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map sentiment label to emotion\n",
        "def map_sentiment_to_emotion(sentiment_label):\n",
        "    if sentiment_label == 'positive':\n",
        "        return 'joy'\n",
        "    elif sentiment_label == 'negative':\n",
        "        return 'sadness'\n",
        "    else:\n",
        "        return 'neutral'\n"
      ],
      "metadata": {
        "id": "jt7NfT9bOSAG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply sentiment-to-emotion mapping and predict emotion for each text\n",
        "def predict_emotion(text):\n",
        "    # Truncate or pad text to fit model's maximum sequence length\n",
        "    max_seq_length = 512\n",
        "    truncated_text = text[:max_seq_length]  # Truncate text if it exceeds maximum length\n",
        "    # Predict emotion\n",
        "    return emotion_pipeline(truncated_text)[0]['label']"
      ],
      "metadata": {
        "id": "MyTEMrEeOR1Q"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotion'] = df['sentiment'].apply(lambda x: map_sentiment_to_emotion(x.lower()))\n",
        "df['predicted_emotion'] = df['clean_text'].apply(predict_emotion)"
      ],
      "metadata": {
        "id": "NBD4pnVsO688"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "print(\"\\nProcessed DataFrame:\")\n",
        "print(df[['clean_text', 'sentiment', 'emotion', 'predicted_emotion']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yvUqZKCO61I",
        "outputId": "602abc17-5f8e-482b-cc53-ce154d3e9838"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed DataFrame:\n",
            "                                             clean_text sentiment emotion  \\\n",
            "0     a huge fan first one almost big fan second one...  positive     joy   \n",
            "1     after entri phase pas without much set next bi...  positive     joy   \n",
            "2     well happen the mcu run ga the last mcu film l...  positive     joy   \n",
            "3     well ill start say wasnt bad movi it wasnt gre...  positive     joy   \n",
            "4     i enjoy watch quantumania it mostli solid fair...  positive     joy   \n",
            "...                                                 ...       ...     ...   \n",
            "3470  thi film unspeak badit actual wors etern becau...  positive     joy   \n",
            "3471  a fun onei terrif time watch antman wasp quant...  positive     joy   \n",
            "3472  a mani other point far heyday peak mcu movi an...  positive     joy   \n",
            "3473  the mcu current state absolut mess up endgam w...  positive     joy   \n",
            "3474  so im go say great marvel film howev i also wo...  positive     joy   \n",
            "\n",
            "     predicted_emotion  \n",
            "0              LABEL_0  \n",
            "1              LABEL_0  \n",
            "2              LABEL_0  \n",
            "3              LABEL_0  \n",
            "4              LABEL_0  \n",
            "...                ...  \n",
            "3470           LABEL_0  \n",
            "3471           LABEL_0  \n",
            "3472           LABEL_0  \n",
            "3473           LABEL_0  \n",
            "3474           LABEL_0  \n",
            "\n",
            "[3475 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sentiment distribution\n",
        "print(\"\\nSentiment distribution:\")\n",
        "print(df['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueq8bOWoO6ua",
        "outputId": "76c5b1d0-ad86-4ce2-df2a-cca60879d0a6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment distribution:\n",
            "sentiment\n",
            "positive    3197\n",
            "negative     278\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display predicted emotion label distribution\n",
        "print(\"\\nPredicted Emotion Label Distribution:\")\n",
        "print(df['predicted_emotion'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpoZFA2pPGQz",
        "outputId": "5b4ca229-97e3-458e-817a-01e220ab7c85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Emotion Label Distribution:\n",
            "predicted_emotion\n",
            "LABEL_0    3475\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(df['emotion'], df['predicted_emotion'])\n",
        "precision = precision_score(df['emotion'], df['predicted_emotion'], average='weighted')\n",
        "recall = recall_score(df['emotion'], df['predicted_emotion'], average='weighted')\n",
        "f1 = f1_score(df['emotion'], df['predicted_emotion'], average='weighted')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKnV_4APSx4r",
        "outputId": "06179433-3f66-439f-f99a-d4b971f40905"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display evaluation metrics\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtUSl9JLS-_x",
        "outputId": "bb1217e8-c2d4-4e82-918e-6f9c9e1df31d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DistilRoBERTa is derived from the RoBERTa model, which undergoes pretraining on a vast corpus of text drawn from various sources like books, articles, and websites. Although the specific datasets used for RoBERTa's pretraining aren't explicitly disclosed, its pretraining method is similar to BERT's, involving tasks like masked language modeling and next sentence prediction across diverse text samples. DistilRoBERTa is designed to be more lightweight and efficient than RoBERTa, achieved by reducing its parameter count. Generally, DistilRoBERTa comprises around 66 million parameters.\n",
        "\n",
        "For sentiment analysis tasks, the DistilRoBERTa model is fine-tuned using a sentiment analysis pipeline provided by the Transformers library. This fine-tuning process involves adjusting the model's parameters using a smaller dataset specific to sentiment analysis. The sentiment analysis pipeline applies the model to predict the sentiment of text inputs, categorizing them as positive, negative, or neutral. Additionally, the code maps these sentiment labels to corresponding emotions, such as joy, sadness, or neutrality, and predicts the emotion for each text based on the sentiment prediction."
      ],
      "metadata": {
        "id": "4hDsLIoZQHGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "\n",
        "Efficiency: DistilRoBERTa is crafted to be more lightweight and computationally efficient compared to the original RoBERTa model. This quality makes it well-suited for deployment in scenarios where resources are limited, or when there's a need for faster inference times.\n",
        "\n",
        "Pretraining on Diverse Data: Similar to RoBERTa, DistilRoBERTa undergoes pretraining on a vast and varied dataset comprising texts from sources like books, articles, and websites. This wide-ranging training data helps the model grasp a broad spectrum of linguistic patterns and meanings, thereby enhancing its performance on tasks such as sentiment analysis.\n",
        "\n",
        "Fine-Tuning for Sentiment Analysis: DistilRoBERTa undergoes a fine-tuning process specifically tailored for sentiment analysis. Through this process, the model adjusts its parameters based on labeled sentiment data, enabling it to better discern sentiment-related features.\n",
        "\n",
        "Transfer Learning: As a pretrained language model, DistilRoBERTa leverages transfer learning to apply the knowledge gained during pretraining to new tasks. This capability allows the model to achieve promising results on sentiment analysis tasks even with limited task-specific data and training.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Simplified Representation: DistilRoBERTa achieves efficiency by reducing parameters and compressing the original RoBERTa model. However, this simplification may lead to loss of fine-grained linguistic nuances, possibly affecting performance on complex tasks.\n",
        "\n",
        "Limited Training Data for Fine-Tuning: Fine-tuning DistilRoBERTa typically requires a smaller labeled dataset specific to the task, such as sentiment analysis. Obtaining a sufficiently diverse and sizable dataset for fine-tuning can be challenging, especially for niche or domain-specific tasks.\n",
        "\n",
        "Interpretability: Like most deep learning models, understanding DistilRoBERTa's internal workings can be complex. This lack of interpretability makes it difficult to comprehend specific predictions, which may raise concerns in applications requiring transparency or accountability.\n",
        "\n",
        "challenges:\n",
        "\n",
        "Model Selection: Opting for the right pretrained language model and fine-tuning approach for sentiment analysis involves weighing factors such as model size, computational resources, and task complexity."
      ],
      "metadata": {
        "id": "BDxWKYKRQwsI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}